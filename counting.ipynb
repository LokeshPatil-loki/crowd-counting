{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install boxmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from boxmot import BoTSORT\n",
    "from pathlib import Path\n",
    "frame_width, frame_height = 1280,720\n",
    "model = YOLO(\"yolov8l.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw Bounding boxes for each detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawBoundingBox(detections,frame):\n",
    "    for box,cls in zip(detections[0].boxes.xyxy,detections[0].boxes.cls):\n",
    "        if cls == 0:\n",
    "            x1,y1,x2,y2 = map(lambda x:int(x),box)\n",
    "            start_point = (x1, y1)\n",
    "            end_point = (x2, y2)\n",
    "            cv2.rectangle(frame,start_point ,end_point , (0, 255, 0), 2)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH,frame_width)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH,frame_height)\n",
    "ret, frame = cap.read() \n",
    "# tracker = BoTSORT(model_weights=Path('osnet_x0_25_msmt17.pt'),device=\"cuda:0\",fp16=False)\n",
    "while(cap.isOpened()):\n",
    "  \n",
    "    detections = model.predict(frame,verbose=False)\n",
    "    if ret == True: \n",
    "        for box,cls in zip(detections[0].boxes.xyxy,detections[0].boxes.cls):\n",
    "            if cls == 0:\n",
    "                x1,y1,x2,y2 = map(lambda x:int(x),box)\n",
    "                start_point = (x1, y1)\n",
    "                end_point = (x2, y2)\n",
    "                cv2.rectangle(frame,start_point ,end_point , (0, 255, 0), 2)\n",
    "        cv2.imshow('Frame', frame)   \n",
    "        ret, frame = cap.read()         \n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'): \n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release() \n",
    "cv2.destroyAllWindows() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = set()\n",
    "s.add(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_color_based_on_id(id):\n",
    "  colors = [[255, 0, 0], # Red\n",
    "          [0, 255, 0], # Green\n",
    "          [0, 0, 255], # Blue\n",
    "          [255, 255, 0], # Yellow\n",
    "          [255, 0, 255], # Magenta\n",
    "          [0, 255, 255], # Cyan\n",
    "          [128, 128, 128], # Gray\n",
    "          [255, 255, 255], # White\n",
    "          [0, 0, 0], # Black\n",
    "          [192, 192, 192]]\n",
    "  return colors[id % len(colors) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_color_based_on_id(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOTSORT TRACKER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from boxmot import BoTSORT\n",
    "from pathlib import Path\n",
    "frame_width, frame_height = 1280,720\n",
    "model = YOLO(\"yolov8l.pt\")\n",
    "\n",
    "def calculate_color_based_on_id(id):\n",
    "  colors = [[255, 0, 0], # Red\n",
    "          [0, 255, 0], # Green\n",
    "          [0, 0, 255], # Blue\n",
    "          [255, 255, 0], # Yellow\n",
    "          [255, 0, 255], # Magenta\n",
    "          [0, 255, 255], # Cyan\n",
    "          [128, 128, 128], # Gray\n",
    "          [255, 255, 255], # White\n",
    "          [0, 0, 0], # Black\n",
    "          [192, 192, 192]]\n",
    "  return colors[id % len(colors) ]\n",
    "\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH,frame_width)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH,frame_height)\n",
    "ret, frame = cap.read() \n",
    "tracker = BoTSORT(model_weights=Path('osnet_x0_25_msmt17.pt'),device=\"cuda:0\",fp16=False)\n",
    "thickness = 2\n",
    "color = (0,0,255)\n",
    "while(cap.isOpened()):\n",
    "    id_set = set()\n",
    "    detections = model.predict(frame,verbose=False)[0]\n",
    "    results = []\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if np.array(detections.boxes.data.tolist()).ndim < 2:\n",
    "        results = [[0, 0, 0, 0, 0.0922948837280273, 0]] \n",
    "    try:\n",
    "        ts = tracker.update(np.array(detections.boxes.data.tolist()), frame)\n",
    "        xyxys = ts[:,0:4].astype('int') # float64 to int\n",
    "        ids = ts[:, 4].astype('int') # float64 to int \n",
    "        confs = ts[:, 5]\n",
    "        clss = ts[:, 6]\n",
    "        if ts.shape[0] != 0:\n",
    "            for xyxy, id, conf, cls in zip(xyxys, ids, confs, clss):\n",
    "\n",
    "                if cls != 0:\n",
    "                    continue\n",
    "                id_set.add(id)\n",
    "                cv2.rectangle(\n",
    "                    frame,\n",
    "                    (xyxy[0], xyxy[1]),\n",
    "                    (xyxy[2], xyxy[3]),\n",
    "                    calculate_color_based_on_id(id),\n",
    "                    thickness\n",
    "                )\n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    f'id: {id}',\n",
    "                    (xyxy[0], xyxy[1]-10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5,\n",
    "                    calculate_color_based_on_id(id),\n",
    "                    thickness\n",
    "                )\n",
    "            cv2.putText(\n",
    "                    frame,\n",
    "                    f'Count: {len(id_set)}',\n",
    "                    (10, 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5,\n",
    "                    (0,0,0),\n",
    "                    thickness\n",
    "                )\n",
    "            cv2.imshow('Frame', frame)\n",
    "    except Exception as e:\n",
    "         print(\"Error:\",e)\n",
    "         pass\n",
    "    ret, frame = cap.read()         \n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'): \n",
    "            break\n",
    "\n",
    "cap.release() \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-03 12:20:51.067\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mboxmot.appearance.reid_model_factory\u001b[0m:\u001b[36mload_pretrained_weights\u001b[0m:\u001b[36m207\u001b[0m - \u001b[32m\u001b[1mSuccessfully loaded pretrained weights from \"osnet_x0_25_msmt17.pt\"\u001b[0m\n",
      "\u001b[32m2023-11-03 12:20:51.068\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mboxmot.appearance.reid_model_factory\u001b[0m:\u001b[36mload_pretrained_weights\u001b[0m:\u001b[36m211\u001b[0m - \u001b[33m\u001b[1mThe following layers are discarded due to unmatched keys or layer size: ('classifier.weight', 'classifier.bias')\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: too many indices for array: array is 1-dimensional, but 2 were indexed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QObject::moveToThread: Current thread (0x5573814b6d50) is not the object's thread (0x5572db476f40).\n",
      "Cannot move to target thread (0x5573814b6d50)\n",
      "\n",
      "qt.qpa.plugin: Could not load the Qt platform plugin \"wayland\" in \"/home/loki/Development/major-project/RealTime-Webcam/venv/lib/python3.11/site-packages/cv2/qt/plugins\" even though it was found.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from boxmot import BoTSORT,StrongSORT\n",
    "from pathlib import Path\n",
    "frame_width, frame_height = 1280,720\n",
    "model = YOLO(\"yolov8l.pt\")\n",
    "\n",
    "def calculate_color_based_on_id(id):\n",
    "  colors = [[255, 0, 0], # Red\n",
    "          [0, 255, 0], # Green\n",
    "          [0, 0, 255], # Blue\n",
    "          [255, 255, 0], # Yellow\n",
    "          [255, 0, 255], # Magenta\n",
    "          [0, 255, 255], # Cyan\n",
    "          [128, 128, 128], # Gray\n",
    "          [255, 255, 255], # White\n",
    "          [0, 0, 0], # Black\n",
    "          [192, 192, 192]]\n",
    "  return colors[id % len(colors) ]\n",
    "\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(\"./lab.mp4\")\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH,frame_width)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH,frame_height)\n",
    "ret, frame = cap.read() \n",
    "tracker = StrongSORT(model_weights=Path('osnet_x0_25_msmt17.pt'),device=\"cuda:0\",fp16=False)\n",
    "thickness = 2\n",
    "color = (0,0,255)\n",
    "while(cap.isOpened()):\n",
    "    id_set = set()\n",
    "    detections = model.predict(frame,verbose=False)[0]\n",
    "    results = []\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if np.array(detections.boxes.data.tolist()).ndim < 2:\n",
    "        results = [[0, 0, 0, 0, 0.0922948837280273, 0]] \n",
    "    try:\n",
    "        ts = tracker.update(np.array(detections.boxes.data.tolist()), frame)\n",
    "        xyxys = ts[:,0:4].astype('int') # float64 to int\n",
    "        ids = ts[:, 4].astype('int') # float64 to int \n",
    "        confs = ts[:, 5]\n",
    "        clss = ts[:, 6]\n",
    "        if ts.shape[0] != 0:\n",
    "            for xyxy, id, conf, cls in zip(xyxys, ids, confs, clss):\n",
    "\n",
    "                if cls != 0:\n",
    "                    continue\n",
    "                id_set.add(id)\n",
    "                cv2.rectangle(\n",
    "                    frame,\n",
    "                    (xyxy[0], xyxy[1]),\n",
    "                    (xyxy[2], xyxy[3]),\n",
    "                    calculate_color_based_on_id(id),\n",
    "                    thickness\n",
    "                )\n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    f'id: {id}',\n",
    "                    (xyxy[0], xyxy[1]-10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5,\n",
    "                    calculate_color_based_on_id(id),\n",
    "                    thickness\n",
    "                )\n",
    "            cv2.putText(\n",
    "                    frame,\n",
    "                    f'Count: {len(id_set)}',\n",
    "                    (10, 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5,\n",
    "                    (0,0,0),\n",
    "                    thickness\n",
    "                )\n",
    "            cv2.imshow('Frame', frame)\n",
    "    except Exception as e:\n",
    "         print(\"Error:\",e)\n",
    "         pass\n",
    "    ret, frame = cap.read()         \n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'): \n",
    "            break\n",
    "\n",
    "cap.release() \n",
    "cv2.destroyAllWindows() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
